{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Joining Data\n",
    "In this exercise, you join data from multiple data frames together. It is common to import data from multiple SQL tables which are related to each other. Given multiple data frames with one or more related column, you use various join functions from the dplyr tidyverse package to combine them together. \n",
    "\n",
    "\n",
    "## R Features\n",
    "* library()\n",
    "* dbConnect()\n",
    "* print()\n",
    "* dbGetQuery()\n",
    "* glimpse()\n",
    "* nrow() \n",
    "* distinct()\n",
    "* inner_join()\n",
    "* left_join()\n",
    "* right_join()\n",
    "* full_join()\n",
    "* rename()\n",
    "* select()\n",
    "* semi_join()\n",
    "* anti_join()\n",
    "* filter()\n",
    "* dbDisconnect()\n",
    "\n",
    "## Datasets\n",
    "* AdventureWorks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "library(___) # odbc\n",
    "library(___) # DBI\n",
    "library(___) # tidyverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import several related SQL tables\n",
    "Connect to the AdventureWorks SQL database and download some tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Connection string info\n",
    "# Already completed, just run the code block\n",
    "# Everyone uses the same SQL credentials\n",
    "driver_name <- \"ODBC Driver 13 for SQL Server\"\n",
    "server_name <- \"uwc-sqlserver.clients.uw.edu\"\n",
    "database_name <- \"AdventureWorks2016CTP3\" \n",
    "user_id <- \"sqlstudentreader\"\n",
    "password <- \"PA6aX2gAhe4hE!ru$6atru\"\n",
    "\n",
    "# Connect to the database\n",
    "# Store connection in conn variable\n",
    "conn <- ___(odbc::odbc(), \n",
    "                  driver = driver_name, \n",
    "                  server = server_name, \n",
    "                  database = database_name,\n",
    "                  uid = user_id,\n",
    "                  pwd = password)\n",
    "\n",
    "# Print the connection object\n",
    "print(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sales Order Tables\n",
    "Table: Sales.SalesOrderHeader\n",
    "* Primary Key: SalesOrderID (PK)\n",
    "* Foreign Keys: CustomerID, SalesPersonID, TerritoryID, BillToAddressID, ShipToAddressID, ShipMethodID, CurrencyRateID\n",
    "\n",
    "Table: Sales.SalesOrderDetail\n",
    "* Primary Key: SalesOrderDetail\n",
    "* Foreign Keys: SalesOrderID, ProductID, SpecialOfferID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get Sales.SalesOrderHeader\n",
    "sql_select <- \"SELECT * FROM ___\"\n",
    "df_sales_order_header <- conn %>% \n",
    "   ___(___)\n",
    "\n",
    "# Get Sales.SalesOrderDetail\n",
    "sql_select <- \"SELECT * FROM ___\"\n",
    "df_sales_order_detail <- conn %>% \n",
    "   ___(___)\n",
    "\n",
    "# Glimpse results\n",
    "glimpse(___)\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice the number of rows for the two tables. Which table has the larger number of rows? Why? \n",
    "\n",
    "Notice that the SalesOrderID column is present in both tables. In SalesOrderHeader it is the primary key meaning that there is only one row for each unique value. In SalesOrderDetail it is a foreign key and multiple rows may have the same value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Distinct()\n",
    "\n",
    "Select distinct/unique rows. Retain only unique/distinct rows from an input tbl. This is similar to unique.data.frame, but considerably faster. \n",
    "\n",
    "distinct(.data, ..., .keep_all = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# View help on distinct()\n",
    "?___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the row count for \n",
    "# Sales.SalesOrderHeader\n",
    "# Hint: nrow()\n",
    "df_sales_order_header %>% \n",
    "   ___()\n",
    "\n",
    "# Get the distinct row count for \n",
    "# Sales.SalesOrderHeader/SalesOrderID\n",
    "# Hint: distinct() and nrow()\n",
    "df_sales_order_header %>% \n",
    "   ___(___) %>% \n",
    "   ___()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that the overall row count and the distinct row count for SalesOrderID is the same. This is required for the primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the row count for \n",
    "# Sales.SalesOrderDetail\n",
    "# Hint: nrow()\n",
    "df_sales_order_detail %>% \n",
    "   ___()\n",
    "\n",
    "# Get the distinct row count for \n",
    "# Sales.SalesOrderDetail/SalesOrderID\n",
    "# Hint: distinct() and nrow()\n",
    "df_sales_order_detail %>% \n",
    "   ___(___) %>% \n",
    "   ___()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that the overall row count is much larger than the distinct values of SalesOrderID. This is because SalesOrderID is a foreign key with values used more than once. The grain of the sales order *detail* table is one row per sales transaction AND product ID. This allows storing of quantity of each product purchased. In contrast, the sales order *header* does not contain product ID or its quantity purchased. \n",
    "\n",
    "Also notice that the unique values matched the number of rows for the sales order header table. This is a sign of clean data with SQL referrential integrity enabled to ensure that they match. There can be no header row without a detail row. There can be no detail row without a header row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Joins\n",
    "Join two tables together. \n",
    "\n",
    "### Usage\n",
    "inner_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ...)\n",
    "\n",
    "left_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ...)\n",
    "\n",
    "right_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ...)\n",
    "\n",
    "full_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ...)\n",
    "\n",
    "semi_join(x, y, by = NULL, copy = FALSE, ...)\n",
    "\n",
    "anti_join(x, y, by = NULL, copy = FALSE, ...)\n",
    "\n",
    "### Arguments\n",
    "* x, y tbls to join\n",
    "* by a character vector of variables to join by. If NULL, the default, join will do a natural join, using all variables with common names across the two tables. A message lists the variables so that you can check they're right (to suppress the message, simply explicitly list the variables that you want to join). To join by different variables on x and y use a named vector. For example, by = c(\"a\" = \"b\") will match x.a to y.b.\n",
    "\n",
    "### Join types\n",
    "Currently dplyr supports four join types: \n",
    "* inner_join return all rows from x where there are matching values in y, and all columns from x and y. If there are multiple matches between x and y, all combination of the matches are returned.\n",
    "* left_join return all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned.\n",
    "* right_join return all rows from y, and all columns from x and y. Rows in y with no match in x will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned.\n",
    "* semi_join return all rows from x where there are matching values in y, keeping just columns from x. A semi join differs from an inner join because an inner join will return one row of x for each matching row of y, where a semi join will never duplicate rows of x.\n",
    "* anti_join return all rows from x where there are not matching values in y, keeping just columns from x.\n",
    "* full_join return all rows and all columns from both x and y. Where there are not matching values, returns NA for the one missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# View help on inner join\n",
    "?___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join Sales.SalesOrderHeader and Sales.SalesOrderDetails\n",
    "# using inner_join() \n",
    "# using automatic join column (omit the 'by' parameter)\n",
    "# store as df_sales_order_inner\n",
    "df_sales_order_inner <- df_sales_order_header %>%\n",
    "   ___(___)\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice the error message in red and the number of rows returned. inner_join() selected all the columns that had matching names between the two dataframes as its best guess for which columms to join on. Although we wanted to join on the primary key which was just SalesOrderID, there were two more columns in common between the two tables, rowguid and ModifiedDate. The values of all three columns needed to match exactly in order to return any rows. Thus no rows were returned because there were no exact matches. \n",
    "\n",
    "Notice the columns are all the columns from the left table plus all the columns from the right table...except there is only one set of join columns. There is only one instance of SalesOrderID and the other two join columns. This makes sense because the join is looking for matching values from the two tables. If there was a SalesOrderID from the left table and a different SalesOrderID from the right table, they would always contain the same value so there is no need to include the join columns more than once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Inner join vs left join vs right join vs full join\n",
    "In the above example, no rows were returned because of two reasons. The first is that it used three columns to join with, called a composite key which is a primary key that contains multiple columns. The second is that inner join was used which requires exact matches from the left and the right tables. \n",
    "\n",
    "We will fix the join criteria issue in a moment, but first let's illustrate the difference among the different join types for the same join columns for these two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join Sales.SalesOrderHeader and Sales.SalesOrderDetails\n",
    "# using left_join() \n",
    "# using automatic join column (omit the 'by' parameter)\n",
    "# store as df_sales_order_left\n",
    "df_sales_order_left <- df_sales_order_header %>%\n",
    "   ___(___)\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice the number of rows returned from the left join. Does this match one of the source tables, SalesOrderHeader or SalesOrderDetail?\n",
    "\n",
    "It should match SalesOrderHeader because it was the *left* table in the join AND there were no matches to the right table. Left joins preserve all the rows in the left table. \n",
    "\n",
    "Also notice the values of the columns from SalesOrderDetail. They are all NA. This is also common because if there isn't a match between the left and right tables, the row from the left table is inserted and NA values are used as placeholders for the right table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join Sales.SalesOrderHeader and Sales.SalesOrderDetails\n",
    "# using right_join() \n",
    "# using automatic join column (omit the 'by' parameter)\n",
    "# store as df_sales_order_right\n",
    "df_sales_order_right <- df_sales_order_header %>%\n",
    "   ___(___)\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How many rows were returned? Which table does it match, SalesOrderHeader or SalesOrderDetail? \n",
    "\n",
    "Similar to left join, right join retained all the rows from the right table and filled in NA values for the left table when there are no matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join Sales.SalesOrderHeader and Sales.SalesOrderDetails\n",
    "# using full_join() \n",
    "# using automatic join column (omit the 'by' parameter)\n",
    "# store as df_sales_order_full\n",
    "df_sales_order_full <- df_sales_order_header %>%\n",
    "   ___(___)\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How many rows were returned? Which table does it match, SalesOrderHeader or SalesOrderDetail? \n",
    "\n",
    "The row count is larger than either table. Why? Because full join has charactistics of both left and right joins in that all the rows from the left table and all the rows from the right table are present in the result. Since there were no matches at all between the two table it returned all the rows from SalesOrderHeader plus all the rows from SalesOrderDetail. It filled in NA values as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Using by\n",
    "The reason there were no matches were because by default, the join functions look for the same column names between the two tables and use that. We can specify the by parameter to override this default behavior. \n",
    "\n",
    "There are three different syntax for by:\n",
    "1. by = \"column name\" - use this for the same single column name in both tables\n",
    "2. by = c(\"col_1\", \"col_2\") - use this for the same multiple column names (composite primary keys)\n",
    "3. by = c(\"col_1_left\" = \"col_1_right\", \"col_2_left\" = \"col_2_right\") - use this when the names don't match between the two tables. It also supports composite primary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join Sales.SalesOrderHeader and Sales.SalesOrderDetails\n",
    "# using inner_join() \n",
    "# using by = \"SalesOrderID\"\n",
    "# store as df_sales_order\n",
    "df_sales_order <- df_sales_order_header %>%\n",
    "   ___(___, by = ___)\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How many rows of data were returned? Does it match SalesOrderHeader or SalesOrderDetail? \n",
    "\n",
    "Since there were matches for each and every row of SalesOrderDetail, then the row count matches the number of rows for SalesOrderDetail. \n",
    "\n",
    "Look at the columns closely and compare the number of columns to the previous joins. Do you see any additional columns?\n",
    "\n",
    "Recall that rowguid and ModifiedDate had the same name in both tables and that the auto join feature used these columns in its join earlier. Since we manually specified the join column using the 'by' parameter and didn't include these two columns, it created a naming conflict when combining the two tables together. In order to include the conflicting columns from the left table and the right table, it renamed the columns appending a suffix. A suffix of '.x' means it came from the left table. A suffix of '.y' means it came from the right table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename the conflicting .x and .y columns\n",
    "# using the naming convention <table>_<column>\n",
    "# update df_sales_order\n",
    "df_sales_order <- df_sales_order %>%\n",
    "   rename(___)\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice the renamed columns and the '.x' and '.y' are gone. Renaming columns with the table name helps data traceablity and troubleshooting. Alternatively, if these fields were not needed for the analysis, then consider not importing these columns from SQL in the first place. This saves computer resources and avoids unnecesary clean up work later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Single vs Multiple Dataframes\n",
    "You can continue to join tables and create a single table at the lowest data grain with a large number of columns. This is useful for machine learning algorithms where all the data it processes must be in a single table. \n",
    "\n",
    "For human analysis, however, it might be more effective to have several data frames you can easily join together as required. Consider a data warehouse star schema as a guideline for how to design your dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get Production.Product\n",
    "# exclude metadata columns: rowguid, ModifiedDate\n",
    "sql_select <- \"SELECT * FROM ___\"\n",
    "df_product <- conn %>% \n",
    "   ___(___) %>% \n",
    "   select(___, ___)\n",
    "\n",
    "# Get Sales.SalesTerritory\n",
    "# exclude metadata columns: rowguid, ModifiedDate\n",
    "sql_select <- \"SELECT * FROM ___\"\n",
    "df_sales_territory <- conn %>% \n",
    "   ___(___) %>% \n",
    "   select(___, ___)\n",
    "\n",
    "# Glimpse results\n",
    "glimpse(___)\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# left join df_sales_order with\n",
    "# df_product and df_sales_territory\n",
    "# store df_sales_order_complete\n",
    "# do not specify the by parameter\n",
    "df_sales_order_complete <- df_sales_order %>% \n",
    "   ___(___) %>% \n",
    "   ___(___)\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice the warning message from the automatic by parameter. Were these the join columns you expected? \n",
    "\n",
    "This is a convenient way to help determine the by parameter and alert you to any potential issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# left join df_sales_order with\n",
    "# df_product and df_sales_territory\n",
    "# rename the Name columns to <table>_Name before joining\n",
    "# store df_sales_order_complete\n",
    "# do not specify the by parameter\n",
    "df_sales_order_complete <- df_sales_order %>% \n",
    "   ___(___ %>% rename(___)) %>% \n",
    "   ___(___ %>% rename(___))\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Are the rows of data what you expected? \n",
    "\n",
    "Adding in lookup or dimension tables shouldn't increase the row count from the underlying transaction or fact table. Always look at the row count from joins. The row count may alert you to when data is messy or the grain of the table is not what you expected. Using a left join instead of an inner join ensure that no transaction rows get removed. \n",
    "\n",
    "Notice that you can alter the left and right join tables inline in the code. Once the Name columns were renamed before joining, the auto join feature worked as expected. If the warning message bothers you, you can always specify the join criteria explicitly. If you practice defensive programming, you would be explicit whenever possible as opposed to relying on automatic behavior which could have unexpected results if the input data changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Semi_join() and Anti_join()\n",
    "If you don't want to join all the data into a single table, you will have some sort of related dataframes that you may need to join together for analysis purposes. semi_join() and anti_join() are useful in situations where you want to filter one dataframe by some criteria in another dataframe but do *not* need the data from the other dataframe. \n",
    "\n",
    "semi and anti joins perform the join but don't add any of the rows from the right table. They simply filter the left table. A semi join retains rows when there is a match with the right table. anti join has the opposite behavior, retains only the rows *not* in the right table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# semi join df_sales_order\n",
    "# with df_sales_territory\n",
    "# glimpse result, do not store in variable\n",
    "df_sales_order %>% ___(___) %>% \n",
    "   glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Is the row count what you expected? Are there any SalesTerritory columns part of the result? \n",
    "\n",
    "Semi join matched on TerritoryID for each and every row. This is an indication of clean source data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# anti join df_sales_order\n",
    "# with df_sales_territory\n",
    "# glimpse result, do not store in variable\n",
    "df_sales_order %>% ___(___) %>% \n",
    "   glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Are the rows returned what you expected? \n",
    "\n",
    "Since anti_join is the opposite from semi_join, if semi_join matched all the rows then anti_join matched 0 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# semi join df_sales_order\n",
    "# with df_sales_territory\n",
    "# inline filtered on CountryRegionCode == \"US\"\n",
    "# glimpse result, do not store in variable\n",
    "df_sales_order %>% ___(___ %>% filter(___)) %>% \n",
    "   glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Is the row count what you expected? \n",
    "\n",
    "There are fewer rows in the result reflecting the filtering of only US sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# anti join df_sales_order\n",
    "# with df_sales_territory\n",
    "# inline filtered on Group == \"North America\"\n",
    "# glimpse result, do not store in variable\n",
    "df_sales_order %>% ___(___ %>% filter(___)) %>% \n",
    "   glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Is the row count what you expected? \n",
    "\n",
    "These results are the sales from all territory groups except for North America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Close SQL connection\n",
    "conn %>% ___()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It is good practice to close the connection when done to conserve resources. Often the connection will automatically close after a timeout duration. If it closes before you wanted it to, just run your dbConnect code again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "Joining is a common data wrangling task as you accumulate more and more dataframes of data. You use joining to organize the data into a design that makes your analysis more agile. You also use joining as a way to explore and filter the data as part of data exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
