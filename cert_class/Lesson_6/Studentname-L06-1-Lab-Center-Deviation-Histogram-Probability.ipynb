{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L06-1 Lab on Central Tendencies, Standard Deviation, Histograms, and Probability \n",
    "\n",
    "## Assignment Instructions\n",
    "Rename with your name in place of Studentname and make your edits and updates here. Run each cell one at a time to make sure you understand what the code is doing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6: Probability and Descriptive Statistics\n",
    "\n",
    "6.A. Initial setup  \n",
    "6.B. Loading and reviewing data  \n",
    "6.1 Introduction to statistics: coding, qualitative vs. quantitative data.  \n",
    "6.2. Mean, Mode, Median, Variance, Standard Deviation  \n",
    "6.3. Probability  \n",
    "6.4. Normal Distribution (Bell-curve)  \n",
    "6.5. Confidence Intervals, Z-Score, T-Scores  \n",
    "6.6. Correlation and Causation  \n",
    "\n",
    "## Purpose\n",
    "Demonstrate an example of descriptive statistics using housing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.A. Initial setup:\n",
    "1. **Update working directory to point to a directory on your computer with AmesHousing.xls file**\n",
    "2. The script installs required packages:\n",
    " * _readxl_ - reads our data from an Excel spreadsheet\n",
    " * _ggplot2_ - plotting\n",
    "3. R doesn't have a function to calculate mode statistic. We will create **stat\\_mode** function to calculate mode, which in turn uses:\n",
    " * _tabulate_ - builds a table of the counts at each combination of factor levels\n",
    " * _which.max_ - return index of the (first) maximum of a numeric (or logical) vector\n",
    " * _match_ - returns a vector of the positions of (first) matches of its first argument in its second\n",
    " * Use ?tabulate, ?match, and ?which.max for additional help\n",
    "4. R's function _mad_ calculated absolute deviation around _median_, but we need deviation around _mean_ - create a function _avgAD_ to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6.A. Initial setup\n",
    "##### On Windows you can use the following command to map a drive to a local directory\n",
    "#> subst U: C:/Users/MyDirectory\n",
    "\n",
    "##### Adjust working directory to match your environment ######\n",
    "##### This directory should contain the data for this exercise: AmesHousing.xls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List contents of working directory\n",
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R doesn't have a method to calculate mode statistic, create one\n",
    "# parameters: \n",
    "#    x - vector of values \n",
    "#    na_rm = FALSE \n",
    "# output: most frequently occuring element in x\n",
    "stat_mode <- function(x, na_rm = FALSE) {\n",
    "  if(na_rm){\n",
    "    x = x[!is.na(x)]\n",
    "  }\n",
    "  \n",
    "  ux <- unique(x)\n",
    "  return(ux[which.max(tabulate(match(x, ux)))])\n",
    "}\n",
    "\n",
    "# R's function mad() calculated absolute deviation around median, but\n",
    "# we need deviation around mean - create a function to calculate\n",
    "# parameters: \n",
    "#    x - vector of values \n",
    "#    na_rm = FALSE \n",
    "# output: absolute deviation around mean\n",
    "avgAD <- function(x, na_rm = FALSE)\n",
    "{\n",
    "  if(na_rm){\n",
    "    x = x[!is.na(x)]\n",
    "  }\n",
    "  return(sum(abs(mean(x)-x))/length(x))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "library(readxl)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(corrgram)\n",
    "library(caret)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.B. Loading and Reviewing Data\n",
    "Recall our discussion about qualitative and quantitative data. R models require us to assign numeric values to character data or “code” character data so we can apply statistical techniques.  R simplifies this procedure with _**as.factor**_ function that will assign different numbers  to each distinct qualitative variable (such as Lot Shape) in our data. Much like in the example in the lesson, addition and subtraction or comparison of qualitative data is not meaningful. For example, Irregular Lot is not bigger than regular lot - they are just different from each other (or belong to different classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6.B. Load and review data\n",
    "#load data\n",
    "AmesHousing<-readxl::read_excel(\"AmesHousing.xls\")\n",
    "\n",
    "#Display first 10 rows\n",
    "head(AmesHousing, 10)\n",
    "str(AmesHousing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1. Introduction to statistics: coding, qualitative vs. quantitative data.\n",
    "We see that our numeric data is loaded to num typed fields.\n",
    "\n",
    "However R needs us to code character data to numbers so we can use statistical algorithms.\n",
    "\n",
    "R simplifies this procedure with **_as.factor()_** function that will assign different numbers  to each distinct qualitative variable (such as Lot Shape) in our data. Much like in the example in the video lesson addition and subtraction or comparison of qualitative data is not meaningful. For example Irregular Lot is not bigger than regular lot - they are just different from each other or belong to different classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.1. Introduction to statistics, including: \n",
    "#    operationalization of concepts (concept to number conversion), \n",
    "#    qualitative vs. quantitative data.\n",
    "\n",
    "#get index of character columns\n",
    "i <- sapply(AmesHousing, is.character)\n",
    "\n",
    "#set character columns to factors\n",
    "AmesHousing[i] <- lapply(AmesHousing[i], as.factor)\n",
    "\n",
    "#check data\n",
    "head(AmesHousing, 10)\n",
    "str(AmesHousing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Central Tendencies & Measures of Dispersion\n",
    "We use several mathematical measurements to determine a central point of our distribution (or central tendency), most typically: mean, median, and mode.\n",
    "\n",
    "$mean = \\frac{1}{n}\\sum{(x_i)}$, where n=number of samples\n",
    "\n",
    "$median =  \\begin{cases}\n",
    "               \\mbox{when count values is odd: the value on the middle of ordered values}\\\\\n",
    "               \\mbox{when count values is even: average of two value on the middle of ordered values}\\\\\n",
    "            \\end{cases}$\n",
    "\n",
    "$mode = \\mbox{most frequent value}$\n",
    "\n",
    "$StandardDeviation = \\frac{1}{n}\\sqrt{\\sum{(x_i - mean)^2}}$\n",
    "\n",
    "$MeanAD = \\frac{1}{n}\\sum{\\mid{(x_i - mean)}\\mid}$\n",
    "\n",
    "$MedianAD = \\frac{b}{n}\\sum{\\mid{(x_i - median)}\\mid}$, where $b=\\frac{1}{.75\\_quantile\\_of\\_underlying\\_distribution}$\n",
    "b=1.4826 for normally distributed data. \n",
    "\n",
    "**Notes:** \n",
    "1. _central tendency functions have a parameter **na.rm** which removes NAs from calculations_, else a function will fail when it encounters NA\n",
    "2. [Leys et al. 2012](https://www.academia.edu/5324493/Detecting_outliers_Do_not_use_standard_deviation_around_the_mean_use_absolute_deviation_around_the_median) advocating for using Median Absolute Deviation for outlier detection (more in the next lesson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?group_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?summarise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6.2 Central tendencies & measure of dispersion\n",
    "\n",
    "#group AmesHousing$SalePrice by price and calculate count in each group\n",
    "grouped_pricing <- AmesHousing %>%\n",
    "    group_by(SalePrice) %>%\n",
    "    summarise(count=n())\n",
    "\n",
    "# Visualize grouped pricing\n",
    "plot(grouped_pricing)\n",
    "\n",
    "#calculate and output central tendencies\n",
    "print(paste(\"mean(SalePrice) =\",mean(AmesHousing$SalePrice)))\n",
    "print(paste(\"median(SalePrice) =\",median(AmesHousing$SalePrice)))\n",
    "print(paste(\"mode(SalePrice) =\",stat_mode(AmesHousing$SalePrice)))\n",
    "\n",
    "#mode is more interesting for factors. Note that most of the lots have regular = 'Reg'shape.\n",
    "print(paste(\"mode(Lot Shape) =\",stat_mode(AmesHousing$'Lot Shape')))\n",
    "#median(AmesHousing$'Lot Shape') - wouldn't work - Error: need numeric data\n",
    "\n",
    "#standard deviation\n",
    "print(paste(\"standard deviation (SalePrice) =\", S <- sd(AmesHousing$SalePrice)))\n",
    "\n",
    "#MAD - median absolute deviation\n",
    "print(paste(\"median absolute deviation (SalePrice) =\", MedianAD <- mad(AmesHousing$SalePrice))) #with scaling\n",
    "print(paste(\"median absolute deviation (SalePrice, b=1) =\",MedianAD <- mad(AmesHousing$SalePrice, constant=1))) #without scaling\n",
    "\n",
    "#MAD - mean absolute deviation\n",
    "print(paste(\"mean absolute deviation (SalePrice) =\",meanAD <- avgAD(AmesHousing$SalePrice)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.C. Viewing statistics for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6.C. Viewing statistics for our data\n",
    "#get histogram information\n",
    "print(\">>> hist() function buckets\")\n",
    "print(histinfo <- hist(AmesHousing$SalePrice, plot = FALSE))\n",
    "\n",
    "#scale density to frequency / count\n",
    "scaleDensity <- max(histinfo$counts)/max(histinfo$density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a ggplot object to draw a Histogram of housing sales price overlaid with density curve.\n",
    "# Assigning ggplot() to an object will allow us to examine internal details.\n",
    "X <- ggplot(AmesHousing, aes(x=SalePrice), environment = environment()) + \n",
    "  geom_histogram(aes(y=..count..),      # Density on y-axis\n",
    "                 bins=length(histinfo$counts),\n",
    "                 color=\"black\", fill=\"white\") +  \n",
    "  eval(substitute(geom_density(aes(y = ..density..*scaleDensity), alpha=.2, fill=\"#FF7777\"), env = list(scaleDensity=scaleDensity))) + # Overlay with density plot\n",
    "  geom_vline(aes(xintercept=mean(SalePrice), color=\"mean\"), linetype=\"dashed\", size=1) + #vertical line for mean\n",
    "  geom_vline(aes(xintercept=median(SalePrice), color=\"median\"), linetype=\"dashed\", size=1) + #vertical line for mean\n",
    "  geom_vline(aes(xintercept=stat_mode(SalePrice), color=\"mode\"), linetype=\"dashed\", size=1) + #vertical line for mode\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)-S, color=\"-1 st. deviation\"), linetype=\"solid\", size=1) + #vertical line for - 1 st. deviation\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)+S, color=\"+1 st. deviation\"), linetype=\"solid\", size=1) + #vertical line for + 1 st. deviation\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)-meanAD, color=\"-1 mean abs dev\"), linetype=\"solid\", size=1) + #vertical line for - 1 st. deviation\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)+meanAD, color=\"+1 mean abs dev\"), linetype=\"solid\", size=1) + #vertical line for + 1 st. deviation\n",
    "  scale_color_manual(values = c(\"mean\"=\"red\", \"median\"=\"green\", \"mode\"=\"blue\", \n",
    "                                \"-1 st. deviation\"=\"gold\", \"+1 st. deviation\"=\"gold4\",\n",
    "                                \"-1 mean abs dev\"=\"magenta\", \"+1 mean abs dev\"=\"magenta4\"\n",
    "  ))\n",
    "\n",
    "#plot histogram\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#examine ggplot() histogram details, notice while we used the number of buckets from hist()\n",
    "#ggplot has it's own bucketing algorithm\n",
    "print(\">>> ggplot() function buckets\")\n",
    "ggplot_build(X)$data[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3. Probability\n",
    "\n",
    "Probability is the measure of the likelihood that an event will occur on a scale from 0 to 1. Or if put in percentage terms 0% - 100%, where 0 indicates impossibility and 1 indicates certainty. \n",
    "\n",
    "A simple example of probability is the tossing of a fair (unbiased) coin. We have 50% probability of heads and 50% probability of tail.\n",
    "\n",
    "Notice that on a small number of tosses we are substantially different from 50/50 heads/tails proportion. In the small sample - we may see more than twice as many tails as we see heads. Try a quarter coin toss at home and compare you results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coin flip experiment\n",
    "set.seed(0)\n",
    "\n",
    "coinToss <- sample(c(\"heads\",\"tails\"), 10, replace = TRUE)\n",
    "table(coinToss)\n",
    "\n",
    "coinToss <- sample(c(\"heads\",\"tails\"), 100, replace = TRUE)\n",
    "table(coinToss)\n",
    "\n",
    "coinToss <- sample(c(\"heads\",\"tails\"), 1000, replace = TRUE)\n",
    "table(coinToss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4. Normal Distribution (Bell-curve), Central Limit Theorem\n",
    "R has several functions that help us to explore normal distribution:\n",
    "* **dnorm**(x, mean = 0, sd = 1, log = FALSE) **probability density of normal distribution** or relative likelihood for a random variable **x** to have a given value \n",
    "* **pnorm**(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) **cumulative distribution** or an area under the cuve of the function _dnrom()_ \n",
    "* **qnorm**(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) **quantile of normal distribution**, \n",
    " * **qnorm()**  is inverse (\"reverses\") of _pnorm()_\n",
    " * **p** is the cummulative probability parameter \n",
    " * returns a value z* corresponding to p, where \n",
    "   * **P(x > z*) < (1-p)** for **qnorm(p, lower.tail = TRUE)**\n",
    "   * and **P(x < z*) < p** for **qnorm(p, lower.tail = FALSE)**\n",
    "   * i.e. probability of observing random normally distributed variable x outside of [-z\\*, z\\*] interval is (1-p)*2 \n",
    "   * example: we use 97.5% quantile for 95% confidence level because 97.5% gives us 2.5% probability on each tail of the distribution 2.5% + 2.5% = 5% total that x will be outside of [-z\\*, z\\*]\n",
    "* **rnorm**(n, mean = 0, sd = 1) **random numbers from normal distribution** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?xlim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?stat_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw various normal distribution graphs\n",
    "xRange = 9 #x=[-xRange, + xRange]\n",
    "\n",
    "ggplot(data.frame(x = c(-xRange , xRange)), aes(x = x)) + \n",
    "  xlim(c(-xRange , xRange)) + \n",
    "  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(colour = \"N(0,1)\")) + \n",
    "  stat_function(fun = dnorm, args = list(mean = 0, sd = 3), aes(colour = \"N(0,3)\")) + \n",
    "  stat_function(fun = dnorm, args = list(mean = 2, sd = 2), aes(colour = \"N(2,2)\")) +\n",
    "  labs(x = \"\\n x\", y = \"dnorm(x) \\n\", title = \"Normal Distribution N(mean, sd) \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw various cummulative probability graphs\n",
    "ggplot(data.frame(x = c(-xRange , xRange)), aes(x = x)) + \n",
    "  xlim(c(-xRange , xRange)) + \n",
    "  stat_function(fun = pnorm, args = list(mean = 0, sd = 1), aes(colour = \"N(0,1)\")) + \n",
    "  stat_function(fun = pnorm, args = list(mean = 0, sd = 3), aes(colour = \"N(0,3)\")) + \n",
    "  stat_function(fun = pnorm, args = list(mean = 2, sd = 2), aes(colour = \"N(2,2)\")) +\n",
    "  labs(x = \"\\n x\", y = \"pnorm(x) \\n\", title = \"Cummulative Distribution N(mean, sd) \\n \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Central Limit Theorem\n",
    "#distribution of sample means will be approximately normal\n",
    "set.seed(0)\n",
    "sampleMean <- c()\n",
    "for (i in 1:1000)\n",
    "{\n",
    "  randomSample <- sample(c(0,1), 100, replace=TRUE)\n",
    "  sampleMean[i] <- mean(randomSample)\n",
    "}\n",
    "\n",
    "#plot density function of our coin experiement\n",
    "#notice that it's approximately normal\n",
    "ggplot(data.frame(sampleMean), aes(x = sampleMean)) + \n",
    "           geom_density(aes(y=..density..)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#same \"normality\" is true for the SalesPrice in the housing data\n",
    "#even though the underlying distribution is skewed\n",
    "  set.seed(0)\n",
    "  sampleMean <- c()\n",
    "  for (i in 1:1000)\n",
    "  {\n",
    "    randomSample <- sample(AmesHousing$SalePrice, 100, replace=TRUE)\n",
    "    sampleMean[i] <- mean(randomSample)\n",
    "  }\n",
    "  \n",
    "  ggplot(data.frame(sampleMean), aes(x = sampleMean)) + \n",
    "    geom_density(aes(y=..density..))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.1. Confidence Intervals\n",
    "\n",
    "Now let's see why 95% of normally distributed samples are between +- 2 standard deviation.  \n",
    "Note that qnorm(0.975)=1.95996 ~ 2*sd  \n",
    "\n",
    "What if the population mean is unknown, like in our example of housing prices, and we want to estimate it with a range of possible values?\n",
    "\n",
    "We can estimate using formula:\n",
    "$\\mu=\\bar{x}\\pm[MOE]$, where\n",
    "* MOE = margin of error = $\\frac{z^*\\sigma}{\\sqrt{n}}$\n",
    "* $z^*=\\pm qnorm(CL)$ \n",
    "* CL = confidence level\n",
    "\n",
    "Interval $[\\bar{x}-MOE, \\bar{x}+MOE]$ is exact when the population distribution is normal, and approximately correct when n is large in in other cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.5 Confidence Intervals, Z-Score, T-Scores\n",
    "\n",
    "#95% of normally distributed samples with standard deviation of 1 are in the interval [-1.95996,1.95996]\n",
    "  mu <- 0\n",
    "  sd <- 1\n",
    "  xRange = 4\n",
    "\n",
    "  ggplot(data.frame(x = c(-xRange , xRange)), aes(x = x)) + \n",
    "    xlim(c(-xRange , xRange)) + \n",
    "    stat_function(fun = dnorm, args = list(mean = mu, sd = sd), aes(colour = \"N(mu=0,sd=1)\")) +\n",
    "    geom_vline(aes(xintercept=qnorm(0.975), color=\"upper 97.5% quantile\"), linetype=\"solid\", size=1) +\n",
    "    geom_vline(aes(xintercept=qnorm(0.975, lower.tail = FALSE), color=\"lower 97.5% quantile\"), linetype=\"solid\", size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#95% confidence interval for average house price\n",
    "set.seed(5)\n",
    "\n",
    "#for somlicity assuming the entire housing dataset is complete population \n",
    "mu <- mean(AmesHousing$SalePrice)\n",
    "sd <- sd(AmesHousing$SalePrice)\n",
    "\n",
    "#plot population distribution and 95% probability interval for Population Mean (mu)\n",
    "ggplot(AmesHousing, aes(x=SalePrice)) +\n",
    "  scale_x_continuous(limits=c(1E5,3E5)) +\n",
    "  geom_density(aes(y = ..density..), alpha=.2, fill=\"#FF7777\") + # Overlay with density plot\n",
    "  geom_vline(aes(xintercept=mu, color=\"mean\"), linetype=\"dashed\", size=1) +\n",
    "  geom_vline(aes(xintercept=mu-qnorm(0.975)*sd/sqrt(length(SalePrice)), color=\"lower margin\"), size=1) +\n",
    "  geom_vline(aes(xintercept=mu+qnorm(0.975)*sd/sqrt(length(SalePrice)), color=\"upper margin\"), size=1) +\n",
    "  labs(title = \"Population Mean (mu) with 95% Probability Interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mall sample population distribution and 95% Confidence Interval for the estimate of Population Mean (mu)\n",
    "#note that interval is quite \"wide\"\n",
    "sample_size <- 25\n",
    "sample <- AmesHousing[sample(1:nrow(AmesHousing), sample_size),]\n",
    "\n",
    "ggplot(sample, aes(x=SalePrice)) +\n",
    "  scale_x_continuous(limits=c(1E5,3E5)) +\n",
    "  geom_density(aes(y = ..density..), alpha=.2, fill=\"#FF7777\") + # Overlay with density plot\n",
    "  geom_vline(aes(xintercept=mean(SalePrice), color=\"mean\"), linetype=\"dashed\", size=1) +\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)-qnorm(0.975)*sd/sqrt(sample_size), color=\"lower margin\"), size=1) +\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)+qnorm(0.975)*sd/sqrt(sample_size), color=\"upper margin\"), size=1) +\n",
    "  labs(title = paste(\"95% Confidence Interval For mu Estimate, sample size=\",sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#larger sample population distribution and 95% Confidence Interval for the estimate of Population Mean (mu)\n",
    "#note that interval is \"narrow\"\n",
    "#note that both confidence intervals include the actual population mean\n",
    "sample_size <- 250\n",
    "sample <- AmesHousing[sample(1:nrow(AmesHousing), sample_size),]\n",
    "\n",
    "ggplot(sample, aes(x=SalePrice)) +\n",
    "  scale_x_continuous(limits=c(1E5,3E5)) +\n",
    "  geom_density(aes(y = ..density..), alpha=.2, fill=\"#FF7777\") + # Overlay with density plot\n",
    "  geom_vline(aes(xintercept=mean(SalePrice), color=\"mean\"), linetype=\"dashed\", size=1) +\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)-qnorm(0.975)*sd/sqrt(sample_size), color=\"lower margin\"), size=1) +\n",
    "  geom_vline(aes(xintercept=mean(SalePrice)+qnorm(0.975)*sd/sqrt(sample_size), color=\"upper margin\"), size=1) +\n",
    "  labs(title = paste(\"95% Confidence Interval For mu Estimate, sample size=\",sample_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.2. Z-Score, T-Scores\n",
    "\n",
    "$Z=\\frac{x-\\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?cbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#note how scaling brings data to the same order of magnitude\n",
    "head(cbind(AmesHousing$SalePrice,  AmesHousing$`Gr Liv Area`), 10)\n",
    "head(cbind(scale(AmesHousing$SalePrice),  scale(AmesHousing$`Gr Liv Area`)), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#note that scaling maintains the relationship between data and \"centers\" data around 0\n",
    "ggplot(AmesHousing,aes(x = SalePrice, y=`Gr Liv Area`)) +\n",
    "    geom_point(shape=1) \n",
    "  \n",
    "ggplot(AmesHousing,aes(x = scale(SalePrice), y=scale(`Gr Liv Area`))) +\n",
    "    geom_point(shape=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6. Correlation\n",
    "\n",
    "Correlation – an extent of linear relationship Expressed by correlation coefficient r: \n",
    "\tr  [-1, 1]\n",
    "\t0 – no relationship\n",
    "\t-1 or 1 – perfect correlation\n",
    "\n",
    "R has a number of functions to help working with correlation  \n",
    "**cor()** - returns correlation matrix  \n",
    "**findCorrelation()** - identifies variables that have correlation higher than specified cutoff with other variables; note the function doesn't return variables that are highly correlated with each other;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate correlation matrix on numeric attributes\n",
    "corMatrix <- cor(na.omit(AmesHousing[, sapply(AmesHousing, is.numeric)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display the correlation between 2 attributes in the matrix and the correlation coefficent\n",
    "(corMatrix <- cor(na.omit(AmesHousing[, c(\"SalePrice\", \"Gr Liv Area\")])))\n",
    "corMatrix[c(\"SalePrice\"),c(\"Gr Liv Area\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?findCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find attributes that are highly correlated ( >0.75) in the matrix\n",
    "highCorr <- findCorrelation(corMatrix, cutoff=0.75,  verbose = FALSE, TRUE)\n",
    "print(\"Fields with > .75 correlation: \")\n",
    "print(paste(\"    \", highCorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Zero-out lower triangle of the matrix to only show (A,B) pairs, rather than (A,B) and (B,A)\n",
    "corMatrix[lower.tri(corMatrix)] <- 0\n",
    "\n",
    "#prepare and use gather() function to unpivot our matrix\n",
    "X <- as.data.frame(corMatrix)\n",
    "X$var1 <- rownames(X)\n",
    "Y <- gather(X, var1, correlation)\n",
    "colnames(Y)[2] = \"var2\"\n",
    "\n",
    "#Display highly correlated attributes. Note the variable match to findCorrelation()\n",
    "filter(arrange(Y, desc(correlation)), correlation < 1 & correlation > .75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graphical presentation of correlation matrix\n",
    "corrgram(corMatrix, order=TRUE, lower.panel=NULL, upper.panel=panel.pie, cex.labels = .5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# End of Lab\n",
    "\n",
    "You are now ready to acquire hands-on experience with descriptive statistics and associated plots.\n",
    "\n",
    "## Please move on to the HW-Probability-Descriptive-Statistics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
